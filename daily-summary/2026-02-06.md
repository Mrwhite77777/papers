# CV 论文日报 - 2026-02-06

## 论文 1: Predicting Camera Pose from Perspective Descriptions for Spatial Reasoning

- **论文链接**: https://arxiv.org/abs/2602.06041
- **作者**: Xuejun Zhang
- **创新点**:
  - 提出CAMCUE框架，将相机位姿作为显式几何锚点，用于跨视角融合和新视角推理
  - 将每视角的位姿注入视觉token中，并将自然语言视角描述映射到目标相机位姿
  - 合成位姿条件化的目标想象视图来支持问题回答
  - 构建了包含27,668个训练样本和508个测试样本的CAMCUE-DATA数据集

- **意义**: 该研究首次实现了从自然语言描述中预测相机位姿的能力，为多视角空间推理提供了新范式。CAMCUE在精度上提升了9.06%，并将推理时间从256.6秒降至1.45秒，使得实时交互成为可能，对机器人导航、AR/VR等应用具有重要价值。

---

## 论文 2: SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs

- **论文链接**: https://arxiv.org/abs/2602.06040
- **作者**: Shilin Yan
- **创新点**:
  - 提出SwimBird，一个推理模式可切换的多模态大语言模型，能根据输入动态在三种推理模式间切换
  - 三种模式包括：(1)纯文本推理，(2)纯视觉推理，(3)视觉-文本交织推理
  - 采用混合自回归公式，统一了文本思维的next-token预测和视觉思维的next-embedding预测
  - 构建了涵盖三种推理模式的SwimBird-SFT-92K监督微调数据集

- **意义**: SwimBird突破了现有MLLM固定推理模式的限制，实现了查询自适应的模式选择。它在保持强文本逻辑的同时显著提升了视觉密集型任务的性能，在多个基准上达到了最先进水平，为多模态推理提供了更灵活的框架。

---

## 论文 3: Thinking with Geometry: Active Geometry Integration for Spatial Reasoning

- **论文链接**: https://arxiv.org/abs/2602.06037
- **作者**: Haoyuan Li
- **创新点**:
  - 提出GeoThinker框架，从被动几何融合转向主动几何感知
  - 模型能够根据内部推理需求有选择地检索几何证据
  - 在精心选择的VLM层应用空间融合，语义视觉先验通过严格的跨注意力查询和集成任务相关几何
  - 通过重要性门控机制将每帧注意力偏向任务相关结构

- **意义**: GeoThinker在空间智能方面设立了新标准，在VSI-Bench上达到72.6分的峰值表现。它展示了强大的泛化能力和显著改进的空间感知能力，对具身引用、自动驾驶等复杂下游场景具有重要意义。

---

## 论文 4: InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions

- **论文链接**: https://arxiv.org/abs/2602.06035
- **作者**: Sirui Xu
- **创新点**:
  - 提出InterPrior框架，通过大规模模仿预训练和强化学习后训练学习统一的生成控制器
  - 将完整参考模仿专家蒸馏为多功能的、目标条件的变分策略
  - 应用物理扰动进行数据增强，并通过强化学习微调提高在未见目标和初始化上的能力
  - 将重构的潜在技能整合到有效的流形中，产生超越训练数据的运动先验

- **意义**: InterPrior实现了大规模人体-物体交互的生成控制，能够组合和泛化跨不同场景的定位操作技能，同时保持物理一致的全身协调。对机器人、动画、虚拟现实等领域具有重要应用价值。

---

## 论文 5: V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval

- **论文链接**: https://arxiv.org/abs/2602.06034
- **作者**: Chaoyang Wang
- **创新点**:
  - 提出V-Retrver，一个证据驱动的检索框架，将多模态检索重新表述为基于视觉检查的代理推理过程
  - MLLM能够通过外部视觉工具在推理过程中选择性地获取视觉证据
  - 执行多模态交替推理过程，在假设生成和定向视觉验证之间交替
  - 采用基于课程的学习策略，结合监督推理激活、拒绝细化和证据对齐目标的强化学习

- **意义**: V-Retrver克服了现有方法主要依赖语言驱动推理的局限性，在多个多模态检索基准上持续提升检索精度（平均提升23.0%），改善了感知驱动的推理可靠性和泛化能力，对多模态信息检索领域具有重要意义。

---

**总结**: 本日选取的5篇论文主要集中在多模态大语言模型、空间推理、人体-物体交互和多模态检索等前沿领域，代表了计算机视觉与自然语言处理深度融合的最新进展。这些工作不仅在技术上实现了重要突破，也为实际应用提供了更高效、更智能的解决方案。
