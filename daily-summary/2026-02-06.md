# CV 论文日报 - 2026-02-06

## 论文 1: SIDeR: Semantic Identity Decoupling for Unrestricted Face Privacy

- **论文链接**: https://arxiv.org/abs/2602.04994
- **作者**: Zhuosen Bao, Xia Du, Zheng Lin, Jizhe Zhou, Zihan Fang, Jiening Wu, Yuxin Zhang, Zhe Chen, Chi-man Pun, Wei Ni, Jun Luo
- **创新点**:
  - 提出语义身份解耦框架（SIDeR），实现人脸隐私保护的身份信息与视觉表示的分离
  - 利用扩散模型潜在空间的语义引导重组，生成视觉上匿名但对机器可识别身份的对抗性人脸
  - 引入动量驱动的无限制扰动优化和语义-视觉平衡因子，合成多种视觉多样、高度自然的对抗样本
  - 支持基于密码的授权访问恢复功能，在提供正确密码时可恢复原始图像
- **意义**: 在人脸识别深度集成的时代（如在线银行、身份验证），SIDeR 提供了一种有效的隐私保护解决方案，在黑盒场景下达到 99% 的攻击成功率，同时保持机器级身份一致性

---

## 论文 2: UniTrack: Differentiable Graph Representation Learning for Multi-Object Tracking

- **论文链接**: https://arxiv.org/abs/2602.05037
- **作者**: Bishoy Galoaa, Xiangyu Bai, Utsav Nandi, Sai Siddhartha Vivek Dhir Rangoju, Somaieh Amraee, Sarah Ostadabbas
- **创新点**:
  - 提出即插即用的图理论损失函数，通过统一可微分学习直接优化多目标跟踪（MOT）性能
  - 将检测精度、身份保持和时空一致性集成到单个端到端可训练的损失函数中
  - 通过可微图表示学习，使网络能够学习运动连续性和跨帧身份关系的整体表示
  - 可与现有 MOT 系统无缝集成，无需架构修改
- **意义**: UniTrack 在多个跟踪模型和基准测试中展示了一致的性能提升，身份切换减少高达 53%，IDF1 提升 12%，为多目标跟踪提供了一种通用的性能优化方案

---

## 论文 3: VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models

- **论文链接**: https://arxiv.org/abs/2602.05049
- **作者**: Yiye Chen, Yanan Jian, Xiaoyi Dong, Shuxin Cao, Jing Wu, Patricio Vela, Benjamin E. Lundell, Dongdong Chen
- **创新点**:
  - 首次从视觉条件化的角度研究视觉-语言-动作（VLA）模型，发现成功滚动比失败滚动表现出更强的视觉依赖性
  - 提出训练框架，通过在轨迹跟踪代理任务上的偏好优化显式增强 VLA 模型的视觉条件化
  - 在监督微调期间通过潜在空间蒸馏将增强的对齐传递到指令跟随任务
  - 无需架构修改或额外数据收集即可提升视觉条件和任务性能
- **意义**: VLA 模型在机器人操作任务中表现出色，但存在视觉-动作不对齐问题。该方法解决了动作预测对当前视觉状态依赖性弱的问题，提升了 VLA 模型的可靠性

---

## 论文 4: ReGLA: Efficient Receptive-Field Modeling with Gated Linear Attention Network

- **论文链接**: https://arxiv.org/abs/2602.05262
- **作者**: Junzhou Li, Manqi Zhao, Yilin Gao, Zhiheng Yu, Yin Li, Dongsheng Jiang, Li Xiao
- **创新点**:
  - 提出 ReGLA 系列轻量级混合网络，结合高效卷积提取局部特征和 ReLU 门控线性注意力进行全局建模
  - 引入高效大感受野（ELRF）模块，在保持大感受野的同时提高卷积效率
  - 设计 ReLU 门控调制注意力（RGMA）模块，在保持线性复杂度的同时增强局部特征表示
  - 采用多教师蒸馏策略提升下游任务性能
- **意义**: ReGLA-M 在 ImageNet-1K 上达到 80.85% Top-1 准确率（224px），在 512px 下仅 4.98ms 延迟，为高分辨率视觉应用提供了最先进的效率解决方案

---

## 论文 5: PoseGaussian: Pose-Driven Novel View Synthesis for Robust 3D Human Reconstruction

- **论文链接**: https://arxiv.org/abs/2602.05190
- **作者**: Ju Shen, Chen Chen, Tam V. Nguyen, Vijayan K. Asari
- **创新点**:
  - 提出姿态驱动的 Gaussian Splatting 框架，用于高保真度人类新视图合成
  - 人体姿态作为结构先验，与颜色编码器融合以细化深度估计；作为时间线索，通过专用姿态编码器增强帧间时间一致性
  - 将姿态信号嵌入几何和时间阶段，改善鲁棒性和泛化能力
  - 实时渲染性能达到 100 FPS
- **意义**: 该框架专门解决动态人体场景中的挑战（如关节运动和严重自遮挡），在 ZJU-MoCap、THuman2.0 等数据集上达到最先进的感知质量和结构准确度（PSNR 30.86, SSIM 0.979, LPIPS 0.028）
